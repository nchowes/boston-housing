{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metro Boston Housing Analysis: 2013-2021 \n",
    "\n",
    "Extract Transform Load  \n",
    "\n",
    "Metro Boston housing prices and days on market for the period 2013-2021. In this notebook, we access the data, prepare it, and export the prepared results for downstream analysis.\n",
    "\n",
    "Data accessed from Boston Magazine: \"Best places to live, annual single family homes\" web urls.  \n",
    "\n",
    "NCH 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix, radviz\n",
    "from housinganalysis import pulldata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure\n",
    "\n",
    "Specify whether to read the data directly from the web url, or used csv archive in repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_from_web = False #Acquire data from url [true], or use archived csv\n",
    "path_to_data = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "Helper function for data preparation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \"\"\"ETL: prepare and standardize data\"\"\"\n",
    "\n",
    "    #Drop unnamed column \n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    #Corner case, 2017 data deviates from naming conventions metric:year \n",
    "    if any( df.columns.str.contains(\":\") ):\n",
    "        new_names = []\n",
    "        for item in df.columns:\n",
    "            value = item.split(\":\")\n",
    "            if len(value) == 2:\n",
    "                value.reverse()\n",
    "                value = \" \".join(value)\n",
    "            else:\n",
    "                value = value[0]\n",
    "            new_names.append( value )\n",
    "        df.columns = new_names\n",
    "\n",
    "    #Corner case, 2019-2020 data deviates from prior naming convention \n",
    "    if \"One-Year % Change in Price\" in df.columns:\n",
    "        df = df.rename(columns={\"One-Year Change\": \"One-Year Days on Market % Change\"})\n",
    "\n",
    "    #Rename columns with standard modifiers\n",
    "    df = df.rename(columns={\n",
    "        \"Town\":                 \"City/Town\",\n",
    "        \"Unnamed: 0.1\":         \"City/Town\", \n",
    "        \"Neighborhood / Town\":  \"City/Town\",\n",
    "        \"1-Year Change\":        \"One-Year Price % Change\",\n",
    "        \"One-Year Change\":      \"One-Year Price % Change\",\n",
    "        \"5-Year Change\":        \"Five-Year Price % Change\",\n",
    "        \"Five-Year Change\":     \"Five-Year Price % Change\",\n",
    "        \"10-Year Change\":       \"Ten-Year Price % Change\",\n",
    "        \"Ten-Year Change\":      \"Ten-Year Price % Change\",\n",
    "        \"One-Year Change.1\":    \"One-Year Days on Market % Change\", \n",
    "        \"One-Year Change.2\":    \"One-Year Number of Sales % Change\", \n",
    "        })\n",
    "\n",
    "    #Replace substrings in cases were column contains a numeric data (e.g. 2013)\n",
    "    df.columns= df.columns.str.replace('No. of Sales','Number of Sales',regex=True)\n",
    "    df.columns= df.columns.str.replace('Percent Change in Price','Price % Change',regex=True)\n",
    "    df.columns= df.columns.str.replace('DOM','Days on Market',regex=True)\n",
    "\n",
    "    #Reorder price change columns \n",
    "    if \"One-Year Price Change\" in df.columns and \"Five-Year Price Change\" in df.columns:\n",
    "        one_year = df.pop( \"One-Year Price Change\" )\n",
    "        five_year = df.pop( \"Five-Year Price Change\" )\n",
    "\n",
    "        df.insert(df.columns.get_loc(\"Ten-Year Price Change\"), \n",
    "            \"Five-Year Price Change\", five_year)\n",
    "        df.insert(df.columns.get_loc(\"Five-Year Price Change\"), \n",
    "            \"One-Year Price Change\", one_year)\n",
    "\n",
    "    #Remove rows with missing values [all]\n",
    "    df = df[ df.iloc[:,1:].notna().all(axis=1) ]\n",
    "\n",
    "    #Identify cols with formatted numeric data as strings, and convert to int\n",
    "    to_convert = []\n",
    "    for item in df.columns[1:]:\n",
    "        if df[item].dtype == \"object\":\n",
    "                to_convert.append(item)\n",
    "\n",
    "    # Convert formatted strings to numerics\n",
    "    for item in to_convert:\n",
    "        #df[item] = df[item].str.replace(r'\\D', '',regex=True).astype(int)\n",
    "        df[item] = df[item].str.replace(\"\\$|,|%\", '',regex=True).astype(float)\n",
    "\n",
    "\n",
    "    #Reset the index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from web\n",
    "\n",
    "Data is published on the web each year as an html table. We'll read each of the eight years into a dataframe and write a csv archive in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note each source contains data for the year prior, in some instances, multiple years prior. \n",
    "urls = {\n",
    "    \"2013\": \"https://www.bostonmagazine.com/best-places-to-live-2014-single-family-homes/\",\n",
    "    \"2014\": \"https://www.bostonmagazine.com/best-places-to-live-2015-single-family-homes/\",\n",
    "    \"2015\": \"https://www.bostonmagazine.com/best-places-to-live-2016-single-family-homes/\",\n",
    "    \"2016\": \"https://www.bostonmagazine.com/best-places-to-live-2017-single-family-homes/\",\n",
    "    \"2017\": \"https://www.bostonmagazine.com/property/top-places-to-live-2018-single-family-homes/\",\n",
    "    \"2018\": \"https://www.bostonmagazine.com/property/top-places-to-live-2019-single-family-homes/\",\n",
    "    \"2019\": \"https://www.bostonmagazine.com/property/single-family-home-prices/\",\n",
    "    \"2020\": \"https://www.bostonmagazine.com/property/single-family-home-price-chart-2020/\",\n",
    "    \"2021\": \"https://www.bostonmagazine.com/property/single-family-home-price-chart-2021/\"\n",
    "    }\n",
    "#Example url\n",
    "urls['2013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source_from_web:\n",
    "\n",
    "    #get data for a single year\n",
    "    thisyear = \"2013\"\n",
    "    status = pulldata(thisyear, urls[thisyear], path_to_data)\n",
    "\n",
    "    # get data for all years \n",
    "    for year, url in urls.items():\n",
    "        pulldata( year, url, path_to_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the 2013 and 2014 housing data to get a sense of the steps required for data preparation, which we'll need to in order to prototype a helper function. We'll then use this helper function on the full dataset. Note there are a few corner cases not seen in the 2013 and 2014 years that we handle in the function.   \n",
    "\n",
    "We'll need to:\n",
    "+ Drop index column   \n",
    "+ Standardize column names  \n",
    "+ Reorder columns  \n",
    "+ Remove missing values \n",
    "+ Fix column data types (e.g. numerics) \n",
    "\n",
    "And use the following naming conventions...\n",
    "+ Price ($): \"Year + Market Price\"\n",
    "+ Price change (%): \"[One|Five|Ten]-Year Price % Change\"\n",
    "+ Days on market (days): \"Year + Days on Market\"\n",
    "+ Days on market change (%): \"[One]-Year Days on Market % Change\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df13 = pd.read_csv( os.path.join(path_to_data, \"housingData2013.csv\") )\n",
    "df13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the first column, names are messy so we'll use iloc\n",
    "df13 = df13.iloc[:, 1:] \n",
    "\n",
    "#Fix inconsistent names \n",
    "df13 = df13.rename(columns={\n",
    "    \"Unnamed: 0.1\":         \"Town\",\n",
    "    \"One-Year Change\":      \"One-Year Price % Change\",\n",
    "    \"Five-Year Change\":     \"Five-Year Price % Change\",\n",
    "    \"10-Year Change\":       \"Ten-Year Price % Change\",\n",
    "    \"One-Year Change.1\":    \"One-Year Days on Market % Change\" \n",
    "    })\n",
    "\n",
    "# reorder columns \n",
    "one_year = df13.pop('One-Year Price % Change')\n",
    "five_year = df13.pop('Five-Year Price % Change')\n",
    "\n",
    "df13.insert(df13.columns.get_loc('Ten-Year Price % Change'), \n",
    "    'Five-Year Price % Change', five_year)\n",
    "df13.insert(df13.columns.get_loc('Five-Year Price % Change'), \n",
    "    'One-Year Price % Change', one_year)\n",
    "\n",
    "df13.head() \n",
    "\n",
    "#Identify cols with formatted numeric data as strings, and convert to int\n",
    "to_convert = []\n",
    "for item in df13.columns[1:]:\n",
    "   if df13[item].dtype == \"object\":\n",
    "        to_convert.append(item)\n",
    "\n",
    "# Convert formatted strings to numerics\n",
    "for item in to_convert:\n",
    "    df13[item] = df13[item].str.replace(\"\\$|,|%\", '',regex=True).astype(float)\n",
    "\n",
    "#reset index \n",
    "df13 = df13.reset_index(drop=True)\n",
    "df13.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014 Housing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df14 = pd.read_csv( os.path.join(path_to_data, \"housingData2014.csv\") )\n",
    "df14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop first column\n",
    "df14 = df14.drop(columns=[\"Unnamed: 0\"])\n",
    "df14.head()\n",
    "\n",
    "#Fix inconsistent names \n",
    "df14 = df14.rename(columns={\n",
    "    \"One-Year Change\":      \"One-Year Price % Change\",\n",
    "    \"Five-Year Change\":     \"Five-Year Price % Change\",\n",
    "    \"10-Year Change\":       \"Ten-Year Price % Change\",\n",
    "    })\n",
    "\n",
    "#Remove rows with missing values [all]\n",
    "df14 = df14[ df14.iloc[:,1:].notna().all(axis=1) ]\n",
    "\n",
    "#Identify cols with formatted numeric data as strings, and convert to int\n",
    "to_convert = []\n",
    "for item in df14.columns[1:]:\n",
    "   if df14[item].dtype == \"object\":\n",
    "        to_convert.append(item)\n",
    "\n",
    "# Convert formatted strings to numerics\n",
    "for item in to_convert:\n",
    "    df14[item] = df14[item].str.replace(\"\\$|,|%\", '',regex=True).astype(float)\n",
    "\n",
    "#reset index \n",
    "df14 = df14.reset_index(drop=True)\n",
    "df14.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and write data \n",
    "\n",
    "Use `prepare_data` on the full set, and write the data products to disk as housingDataYYYY-prepared.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of data files \n",
    "pattern = \"*\"+('[0-9]'*4)+\".csv\"\n",
    "inventory = sorted(glob.glob( os.path.join(path_to_data, pattern) ))\n",
    "inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in inventory:\n",
    "    df = pd.read_csv(item)\n",
    "\n",
    "    #Corner case\n",
    "    if \"2020\" in item:\n",
    "        ohNineCols =  [\"2009 Median Price\", \"2009 DOM\", \"2009 Sales\"]\n",
    "        df = df.drop(columns=ohNineCols)\n",
    "    df = prepare_data(df)\n",
    "\n",
    "    fileparts = os.path.basename(item).split(\".\")\n",
    "    path_to_output = os.path.join(path_to_data, f\"{fileparts[0]}-prepared.{fileparts[1]}\")\n",
    "    print(path_to_output) \n",
    "\n",
    "    df.to_csv(path_to_output, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2838c29c2454def4ce0bd0e4c5885279dfa5c9a865129853a8424db0ecd78f7a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('steamlit': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
